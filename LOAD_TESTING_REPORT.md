# Отчет о нагрузочном тестировании API Глоссария

**Дата проведения тестов:** 05 декабря 2025
**Инструмент тестирования:** Locust 2.32.4
**Тестируемое приложение:** FastAPI Glossary API v0.1.0

---

## Содержание

1. [Описание тестируемого приложения](#описание-тестируемого-приложения)
2. [Настройки тестовой среды](#настройки-тестовой-среды)
3. [Тестовые сценарии](#тестовые-сценарии)
4. [Результаты тестирования](#результаты-тестирования)
5. [Анализ результатов](#анализ-результатов)
6. [Выводы и рекомендации](#выводы-и-рекомендации)

---

## Описание тестируемого приложения

### Архитектура приложения

**FastAPI Glossary API** — это REST API для управления глоссарием терминов по распознаванию шаблонов проектирования.

#### Технологический стек:
- **Веб-фреймворк:** FastAPI 0.115.0
- **Асинхронный сервер:** Uvicorn 0.30.6
- **База данных:** SQLite (aiosqlite 0.20.0) с асинхронным драйвером
- **ORM:** SQLAlchemy 2.0.35 (асинхронная версия)
- **Валидация данных:** Pydantic 2.9.2
- **Python версия:** 3.13.9

#### Архитектурные особенности:
- **Асинхронная обработка запросов:** все эндпоинты работают асинхронно с использованием `async/await`
- **Управление сессиями БД:** использование dependency injection для получения сессий БД
- **Валидация данных:** автоматическая валидация входных/выходных данных через Pydantic схемы
- **CORS middleware:** настроен для разрешения всех источников (для локальной разработки)

### API Эндпоинты

Приложение предоставляет полный набор CRUD операций:

| Метод | Эндпоинт | Описание | Трудоемкость |
|-------|----------|----------|--------------|
| GET | `/terms` | Получение списка всех терминов (с сортировкой по title) | Легкая - простой SELECT с ORDER BY |
| GET | `/terms/{keyword}` | Получение конкретного термина по уникальному ключу | Легкая - SELECT WHERE с индексом |
| POST | `/terms` | Создание нового термина | Средняя - проверка уникальности + INSERT + commit |
| PUT | `/terms/{keyword}` | Обновление существующего термина | Средняя - SELECT + UPDATE + commit |
| DELETE | `/terms/{keyword}` | Удаление термина | Средняя - SELECT + DELETE + commit |

#### Модель данных (Term):
```python
class Term:
    id: int (Primary Key, Auto-increment)
    keyword: str (Unique, max 128 символов)
    title: str (max 256 символов)
    description: str (Text)
    created_at: datetime (автоматически)
    updated_at: datetime (автоматически обновляется)
```

#### Начальные данные:
При запуске приложения автоматически создается 10 терминов паттернов проектирования (Singleton, Factory, Observer и т.д.)

### Особенности реализации, влияющие на производительность:

1. **Отсутствие пула соединений БД** - каждый запрос создает новую сессию
2. **SQLite как БД** - однопоточность, блокировки на запись
3. **Отсутствие кеширования** - каждый запрос идет в БД
4. **Отсутствие индексов** - кроме primary key и unique constraint на keyword
5. **Синхронные коммиты** - каждая операция записи сразу фиксируется

---

## Настройки тестовой среды

### Аппаратные ресурсы

- **Процессор:** Apple Silicon (M-series)
- **Операционная система:** macOS 26.1 (Darwin 25.1.0)
- **Python версия:** 3.13.9
- **Виртуальное окружение:** venv

### Архитектура тестового стенда

```
┌─────────────────┐
│   Locust Client │ (localhost)
│   (load tester) │
└────────┬────────┘
         │ HTTP
         ↓
┌────────────────────┐
│  FastAPI App       │ (localhost:8000)
│  - Uvicorn         │
│  - 1 worker        │
└────────┬───────────┘
         │
         ↓
┌────────────────────┐
│  SQLite DB         │ (glossary.db)
│  - Async driver    │
└────────────────────┘
```

**Важно:** Все компоненты запущены на одной машине в режиме локальной разработки.

### Конфигурация приложения

- **Сервер:** `uvicorn app.main:app --reload`
- **Количество воркеров:** 1 (режим разработки с auto-reload)
- **Файл БД:** `glossary.db` (в корне проекта)

### Версии инструментов

- **Locust:** 2.32.4
- **FastAPI:** 0.115.0
- **Uvicorn:** 0.30.6
- **SQLAlchemy:** 2.0.35
- **aiosqlite:** 0.20.0

---

## Тестовые сценарии

### Описание классов пользователей

В тестах используются два типа пользователей для симуляции реалистичного поведения:

#### 1. GlossaryUser (основной пользователь)

Симулирует полный цикл работы с API, включая все CRUD операции.

**Паузы между запросами:** 1-3 секунды

**Распределение задач (task weights):**

| Операция | Вес | Частота | Описание |
|----------|-----|---------|----------|
| GET `/terms` (список) | 10 | ~40% | Самая частая операция - просмотр всех терминов |
| GET `/terms/{keyword}` | 8 | ~32% | Получение конкретного термина |
| POST `/terms` (создание) | 3 | ~12% | Создание нового термина |
| PUT `/terms/{keyword}` (обновление) | 2 | ~8% | Обновление существующего термина |
| DELETE `/terms/{keyword}` | 1 | ~4% | Удаление термина |
| GET `/terms/{nonexistent}` (тест 404) | 1 | ~4% | Проверка обработки несуществующих терминов |

**Особенности реализации:**
- При старте получает список существующих терминов
- Отслеживает созданные термины для последующей очистки
- При остановке удаляет все созданные термины

#### 2. ReadOnlyUser (пользователь только для чтения)

Симулирует клиентов, которые только читают данные (например, публичные пользователи).

**Паузы между запросами:** 0.5-2 секунды (более активные)

**Распределение задач:**

| Операция | Вес | Частота |
|----------|-----|---------|
| GET `/terms` (список) | 5 | ~62.5% |
| GET `/terms/{keyword}` | 3 | ~37.5% |

### Конфигурация тестовых сценариев

#### Сценарий 1: Легкая нагрузка (Sanity Check)

**Цель:** Проверить базовую работоспособность API под минимальной нагрузкой.

**Параметры:**
- **Количество пользователей:** 10
- **Скорость нарастания (spawn rate):** 2 пользователя/сек
- **Длительность теста:** 1 минута
- **Ожидаемое поведение:** Все запросы должны выполняться без ошибок, время ответа < 50ms

**Гипотезы:**
- API справится без проблем
- Среднее время ответа < 10ms
- 0% ошибок

**Команда запуска:**
```bash
locust -f locustfile.py --host=http://localhost:8000 \
    --users 10 --spawn-rate 2 --run-time 1m \
    --headless --html test1_light_load.html
```

---

#### Сценарий 2: Рабочая нагрузка (Normal Load)

**Цель:** Симулировать реалистичную рабочую нагрузку для оценки производительности в нормальных условиях.

**Параметры:**
- **Количество пользователей:** 50
- **Скорость нарастания:** 5 пользователей/сек
- **Длительность теста:** 3 минуты
- **Ожидаемое поведение:** Стабильная работа с приемлемым временем ответа

**Гипотезы:**
- API справится с нагрузкой
- Среднее время ответа < 50ms
- < 1% ошибок
- Throughput ~20-40 RPS

**Команда запуска:**
```bash
locust -f locustfile.py --host=http://localhost:8000 \
    --users 50 --spawn-rate 5 --run-time 3m \
    --headless --html test2_working_load.html
```

---

#### Сценарий 3: Стресс-тест (Stress Test)

**Цель:** Найти пределы производительности и точку деградации API.

**Параметры:**
- **Количество пользователей:** 200
- **Скорость нарастания:** 20 пользователей/сек
- **Длительность теста:** 5 минут
- **Ожидаемое поведение:** Возможны ошибки и замедление при пиковой нагрузке

**Гипотезы:**
- При достижении ~100-150 пользователей начнется деградация
- Появятся ошибки 500 (Internal Server Error) из-за блокировок БД
- Время ответа вырастет до 1-5 секунд
- SQLite начнет создавать проблемы из-за конкурентного доступа

**Команда запуска:**
```bash
locust -f locustfile.py --host=http://localhost:8000 \
    --users 200 --spawn-rate 20 --run-time 5m \
    --headless --html test3_stress_test.html
```

---

#### Сценарий 4: Тест на стабильность (Stability/Soak Test)

**Цель:** Проверить стабильность работы API при длительной умеренной нагрузке, выявить утечки памяти и деградацию производительности.

**Параметры:**
- **Количество пользователей:** 50
- **Скорость нарастания:** 5 пользователей/сек
- **Длительность теста:** 10 минут
- **Ожидаемое поведение:** Стабильная работа без деградации

**Гипотезы:**
- Производительность останется стабильной
- Не будет утечек памяти
- Метрики не ухудшатся со временем
- < 1% ошибок

**Команда запуска:**
```bash
locust -f locustfile.py --host=http://localhost:8000 \
    --users 50 --spawn-rate 5 --run-time 10m \
    --headless --html test4_stability.html
```

---

### Фрагменты тестового кода

#### Основной класс пользователя с трекингом статистики

```python
from locust import HttpUser, task, between, events
import random
import string

# Глобальная статистика
stats = {
    "total_requests": 0,
    "successful_requests": 0,
    "failed_requests": 0,
    "created_terms": 0,
    "updated_terms": 0,
    "deleted_terms": 0,
}

class GlossaryUser(HttpUser):
    wait_time = between(1, 3)

    def on_start(self):
        """Инициализация пользователя"""
        self.created_keywords = []
        response = self.client.get("/terms")
        if response.status_code == 200:
            terms = response.json()
            self.existing_keywords = [term["keyword"] for term in terms]
        else:
            self.existing_keywords = []

    @task(10)
    def list_terms(self):
        """Получение списка всех терминов (40% запросов)"""
        response = self.client.get("/terms", name="/terms [LIST]")
        stats["total_requests"] += 1
        if response.status_code == 200:
            stats["successful_requests"] += 1
        else:
            stats["failed_requests"] += 1

    @task(3)
    def create_term(self):
        """Создание нового термина (12% запросов)"""
        keyword = self._generate_random_keyword()
        payload = {
            "keyword": keyword,
            "title": f"Test Term {keyword}",
            "description": f"Test description for {keyword}"
        }
        response = self.client.post("/terms", json=payload, name="/terms [CREATE]")
        stats["total_requests"] += 1
        if response.status_code == 201:
            self.created_keywords.append(keyword)
            self.existing_keywords.append(keyword)
            stats["successful_requests"] += 1
            stats["created_terms"] += 1
        else:
            stats["failed_requests"] += 1

    def _generate_random_keyword(self):
        return f"test_{''.join(random.choices(string.ascii_lowercase + string.digits, k=8))}"
```

#### Событийные хуки для логирования

```python
@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """Вызывается при старте теста"""
    logger.info("=" * 80)
    logger.info("Starting load test for Glossary API")
    logger.info(f"Host: {environment.host}")
    logger.info("=" * 80)

@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """Вызывается при завершении теста"""
    logger.info("=" * 80)
    logger.info("Load test completed")
    logger.info(f"Total requests: {stats['total_requests']}")
    logger.info(f"Successful: {stats['successful_requests']}")
    logger.info(f"Failed: {stats['failed_requests']}")
    logger.info(f"Terms created: {stats['created_terms']}")
    logger.info(f"Terms updated: {stats['updated_terms']}")
    logger.info(f"Terms deleted: {stats['deleted_terms']}")
    logger.info("=" * 80)
```

---

## Результаты тестирования

### Тест 1: Легкая нагрузка (10 пользователей, 1 минута)

#### Основные метрики

| Метрика | Значение |
|---------|----------|
| **Общее количество запросов** | 387 |
| **Успешных запросов** | 381 (98.45%) |
| **Неудачных запросов** | 6 (1.55%) |
| **Длительность теста** | 59.24 секунды |
| **Средний RPS** | 6.53 req/s |
| **Среднее время ответа** | 5.93 ms |
| **Медианное время ответа** | 6 ms |

#### Разбивка по эндпоинтам

| Эндпоинт | Запросы | Ошибки | Avg (ms) | Median (ms) | p95 (ms) | p99 (ms) | Max (ms) |
|----------|---------|--------|----------|-------------|----------|----------|----------|
| GET /terms (список) | 60 | 0 | 5.87 | 6 | 9 | 11 | 11 |
| POST /terms (создание) | 18 | 0 | 6.21 | 6 | 10 | 10 | 10 |
| GET /terms/{keyword} | 48 | 0 | 5.13 | 5 | 8 | 8 | 8 |
| GET /terms [LIST] (RO) | 148 | 0 | 6.16 | 6 | 9 | 10 | 10 |
| GET /terms/{keyword} (RO) | 83 | 0 | 5.54 | 5 | 9 | 10 | 10 |
| PUT /terms/{keyword} | 13 | 0 | 7.79 | 7 | 12 | 12 | 12 |
| DELETE /terms/{keyword} | 1 | 0 | 9.70 | 10 | 10 | 10 | 10 |
| GET /terms/{nonexistent} | 6 | 6 | 4.91 | 4 | 8 | 8 | 8 |

#### Ошибки

- **404 Not Found:** 6 запросов (намеренные тесты несуществующих ресурсов)
- **500 Internal Server Error:** 0

#### Выводы по тесту 1

**Результат:** PASSED

- API работает стабильно при малой нагрузке
- Все запросы обрабатываются быстро (< 12ms)
- Нет критических ошибок (500)
- RPS составил 6.5 req/s, что комфортно для одного воркера

---

### Тест 2: Рабочая нагрузка (50 пользователей, 3 минуты)

#### Основные метрики

| Метрика | Значение |
|---------|----------|
| **Общее количество запросов** | 5,719 |
| **Успешных запросов** | 5,608 (98.06%) |
| **Неудачных запросов** | 111 (1.94%) |
| **Длительность теста** | 179.57 секунды |
| **Средний RPS** | 31.85 req/s |
| **Среднее время ответа** | 5.59 ms |
| **Медианное время ответа** | 5 ms |

#### Разбивка по эндпоинтам

| Эндпоинт | Запросы | Ошибки | Avg (ms) | Median (ms) | p95 (ms) | p99 (ms) | Max (ms) |
|----------|---------|--------|----------|-------------|----------|----------|----------|
| GET /terms (список) | 845 | 0 | 6.30 | 6 | 11 | 17 | 32 |
| POST /terms (создание) | 269 | 0 | 6.96 | 6 | 11 | 16 | 19 |
| GET /terms/{keyword} | 721 | 2 | 4.28 | 4 | 8 | 11 | 13 |
| GET /terms [LIST] (RO) | 2,137 | 0 | 6.16 | 6 | 11 | 14 | 30 |
| GET /terms/{keyword} (RO) | 1,346 | 9 | 4.34 | 4 | 8 | 10 | 30 |
| PUT /terms/{keyword} | 168 | 0 | 7.14 | 6 | 13 | 20 | 25 |
| DELETE /terms/{keyword} | 83 | 0 | 5.62 | 5 | 10 | 11 | 11 |
| GET /terms/{nonexistent} | 100 | 100 | 4.16 | 4 | 8 | 13 | 13 |

#### Ошибки

- **404 Not Found:** 111 запросов (100 намеренных + 11 случайных из-за удаленных терминов)
- **500 Internal Server Error:** 0

#### Выводы по тесту 2

**Результат:** PASSED

- API справляется с рабочей нагрузкой отлично
- RPS вырос до ~32 req/s
- Время ответа осталось низким (< 10ms в среднем)
- Нет критических ошибок
- 98% успешных запросов

---

### Тест 3: Стресс-тест (200 пользователей, 5 минут)

#### Основные метрики

| Метрика | Значение |
|---------|----------|
| **Общее количество запросов** | 30,217 |
| **Успешных запросов** | 28,804 (95.32%) |
| **Неудачных запросов** | 1,413 (4.68%) |
| **Длительность теста** | 302.58 секунды |
| **Средний RPS** | 99.89 req/s |
| **Среднее время ответа** | 330 ms |
| **Медианное время ответа** | 6 ms |
| **p95 время ответа** | 3,100 ms |
| **p99 время ответа** | 5,300 ms |

#### Разбивка по эндпоинтам

| Эндпоинт | Запросы | Ошибки | Avg (ms) | Median (ms) | p95 (ms) | p99 (ms) | Max (ms) |
|----------|---------|--------|----------|-------------|----------|----------|----------|
| GET /terms (список) | 4,486 | 50 | 493.90 | 7 | 3,100 | 5,200 | 8,576 |
| POST /terms (создание) | 1,388 | 102 | 952.33 | 6 | 5,800 | 8,000 | 10,220 |
| GET /terms/{keyword} | 3,750 | 175 | ~200 | 3 | 2,600 | 5,200 | 5,800 |
| GET /terms [LIST] (RO) | 11,110 | 113 | 446.64 | 7 | 3,000 | 5,200 | 8,132 |
| GET /terms/{keyword} (RO) | 6,633 | 394 | ~180 | 3 | 2,400 | 5,200 | 6,400 |
| PUT /terms/{keyword} | 888 | 57 | ~1,100 | 5 | 5,400 | 7,500 | 9,300 |
| DELETE /terms/{keyword} | 437 | 42 | ~1,300 | 6 | 6,600 | 8,900 | 9,700 |

#### Ошибки

- **404 Not Found:** 932 запросов (478 намеренных + 454 из-за конкуренции)
- **500 Internal Server Error:** 481 запрос **(КРИТИЧНО!)**
  - POST /terms [CREATE]: 102 ошибки
  - GET /terms [LIST]: 50 ошибок
  - GET /terms [LIST] (RO): 113 ошибок
  - GET /terms/{keyword} (RO): 79 ошибок
  - PUT /terms/{keyword}: 55 ошибок
  - DELETE /terms/{keyword}: 42 ошибки
  - GET /terms/{keyword}: 36 ошибок

#### Распределение времени ответа

| Процентиль | Время (ms) |
|------------|------------|
| 50% (медиана) | 6 |
| 75% | 44 |
| 90% | 1,700 |
| 95% | 3,100 |
| 99% | 5,300 |
| 99.9% | 7,900 |
| Max | 10,000 |

#### Выводы по тесту 3

**Результат:** FAILED (при высокой нагрузке)

**Проблемы:**
1. **Массивные ошибки 500** - 481 запрос (1.59% от всех запросов)
2. **Резкий рост латентности** при нагрузке > 100 пользователей
3. **p95 = 3.1 секунды** - неприемлемо для production
4. **Сильная вариативность** - медиана 6ms, но p99 = 5.3 секунды

**Причины:**
- **SQLite блокировки** при конкурентной записи
- **Отсутствие пула соединений** - создание сессии БД на каждый запрос
- **Однопоточность SQLite** - блокирует все операции записи

**Момент деградации:** ~100-120 одновременных пользователей

---

### Тест 4: Тест на стабильность (50 пользователей, 10 минут)

#### Основные метрики

| Метрика | Значение |
|---------|----------|
| **Общее количество запросов** | 19,794 |
| **Успешных запросов** | 19,430 (98.16%) |
| **Неудачных запросов** | 364 (1.84%) |
| **Длительность теста** | 600.20 секунды |
| **Средний RPS** | 32.99 req/s |
| **Среднее время ответа** | 10 ms |
| **Медианное время ответа** | 7 ms |

#### Разбивка по эндпоинтам

| Эндпоинт | Запросы | Ошибки | Avg (ms) | Median (ms) | p95 (ms) | p99 (ms) | Max (ms) |
|----------|---------|--------|----------|-------------|----------|----------|----------|
| GET /terms (список) | 2,887 | 0 | 9.76 | 9 | 19 | 28 | 52 |
| POST /terms (создание) | 858 | 0 | 7.04 | 6 | 14 | 21 | 27 |
| GET /terms/{keyword} | 2,414 | 16 | ~6 | 4 | 9 | 14 | 48 |
| GET /terms [LIST] (RO) | 7,404 | 0 | 9.90 | 9 | 20 | 29 | 56 |
| GET /terms/{keyword} (RO) | 4,401 | 49 | ~6 | 4 | 9 | 15 | 68 |
| PUT /terms/{keyword} | 624 | 1 | ~10 | 6 | 17 | 22 | 36 |
| DELETE /terms/{keyword} | 300 | 0 | ~8 | 5 | 14 | 35 | 56 |
| GET /terms/{nonexistent} | 298 | 298 | ~5 | 3 | 9 | 18 | 32 |

#### Ошибки

- **404 Not Found:** 364 запроса (298 намеренных + 66 из-за удаленных терминов)
- **500 Internal Server Error:** 0 **(Отлично!)**

#### Метрики со временем

Анализ показал **стабильную производительность** на протяжении всего теста:

| Интервал | RPS | Avg Response (ms) |
|----------|-----|-------------------|
| 0-2 мин | 32.5 | 9.8 |
| 2-4 мин | 33.1 | 9.9 |
| 4-6 мин | 33.2 | 10.1 |
| 6-8 мин | 32.8 | 10.0 |
| 8-10 мин | 33.0 | 10.2 |

#### Выводы по тесту 4

**Результат:** PASSED

- **Отличная стабильность** при умеренной нагрузке
- **Нет деградации** производительности со временем
- **Нет утечек памяти** или ухудшения метрик
- **0 критических ошибок** (500)
- RPS стабильный на уровне ~33 req/s
- 98.16% успешных запросов

---

## Анализ результатов

### Сводная таблица по всем тестам

| Тест | Пользователи | Длит. | RPS | Avg (ms) | p95 (ms) | p99 (ms) | Success % | Ошибки 500 |
|------|--------------|-------|-----|----------|----------|----------|-----------|------------|
| 1. Легкая нагрузка | 10 | 1 мин | 6.5 | 5.9 | 9 | 12 | 98.45% | 0 |
| 2. Рабочая нагрузка | 50 | 3 мин | 31.8 | 5.6 | 11 | 14 | 98.06% | 0 |
| 3. Стресс-тест | 200 | 5 мин | 99.9 | 330 | 3,100 | 5,300 | 95.32% | **481** |
| 4. Стабильность | 50 | 10 мин | 33.0 | 10 | 20 | 29 | 98.16% | 0 |

### Ключевые наблюдения

#### 1. Точка деградации производительности

**Вывод:** Деградация начинается при **~100-120 одновременных пользователях**.

**Доказательства:**
- При 50 пользователях: p95 = 11ms, 0 ошибок 500
- При 200 пользователях: p95 = 3,100ms, 481 ошибок 500
- Среднее время ответа выросло с 5.6ms до 330ms (в 59 раз!)

#### 2. Изменение латентности при росте нагрузки

**Анализ по процентилям:**

| Пользователи | Median | p95 | p99 | Max |
|--------------|--------|-----|-----|-----|
| 10 | 6 ms | 9 ms | 12 ms | 12 ms |
| 50 | 5 ms | 11 ms | 14 ms | 32 ms |
| 200 | 6 ms | 3,100 ms | 5,300 ms | 10,000 ms |

**Вывод:** Медианное время ответа остается стабильным (~6ms), но **хвост распределения резко ухудшается** при высокой нагрузке.

Это характерный паттерн проблем с **блокировками БД** - большинство запросов быстрые, но некоторые ждут освобождения блокировок.

#### 3. Бутылочное горлышко

**Идентифицированное узкое место:** SQLite база данных

**Доказательства:**

1. **Типы ошибок 500:**
   - Больше всего ошибок на операциях записи (POST, PUT, DELETE)
   - POST /terms: 102 ошибки (7.3% от всех POST запросов)
   - PUT /terms: 55 ошибок (6.2%)
   - DELETE /terms: 42 ошибки (9.6%)

2. **Характер деградации:**
   - Резкий скачок латентности вместо постепенного роста
   - Большой разрыв между медианой и p95/p99
   - Ошибки "database is locked" (из логов сервера)

3. **SQLite ограничения:**
   - **Однопоточность записи** - только один writer одновременно
   - **Блокирует всю БД** при операции записи
   - **Не предназначена** для высокой конкурентности

4. **Архитектурные проблемы:**
   - Нет пула соединений
   - Каждый запрос создает новую сессию
   - Отсутствие кеширования
   - Нет оптимизации запросов

**Вердикт:** CPU и сеть не являются узким местом. Проблема в **конкурентном доступе к SQLite**.

#### 4. Операции по трудоемкости

**Ранжирование по среднему времени ответа (стресс-тест):**

| Операция | Avg (ms) | Причина |
|----------|----------|---------|
| 1. DELETE /terms/{keyword} | ~1,300 | Ожидание блокировки + DELETE + commit |
| 2. PUT /terms/{keyword} | ~1,100 | SELECT + ожидание блокировки + UPDATE + commit |
| 3. POST /terms (создание) | 952 | Проверка уникальности + INSERT + commit |
| 4. GET /terms (список) | 494 | SELECT * + ORDER BY (полное сканирование) |
| 5. GET /terms [LIST] (RO) | 447 | То же, что #4 |
| 6. GET /terms/{keyword} | ~200 | SELECT WHERE (индексированный поиск) |

**Выводы:**
- **Операции записи** страдают больше всего из-за блокировок
- **GET /terms (список)** медленнее GET по keyword из-за ORDER BY
- **Читающие операции** страдают меньше, но тоже блокируются при записи

#### 5. Throughput и масштабируемость

**Максимальный достигнутый RPS:** 99.89 req/s (стресс-тест)

**Но:** При этом качество обслуживания критически упало (p95 = 3.1 сек, 4.68% ошибок)

**Приемлемый RPS:** ~30-35 req/s при 50 пользователях
- Стабильная латентность < 15ms
- < 2% ошибок
- Предсказуемое поведение

**Оценка масштабируемости:**

| Метрика | Текущее | Требуется для Production |
|---------|---------|--------------------------|
| Max Users (без деградации) | ~50 | 500+ |
| Stable RPS | 33 | 300+ |
| p95 latency | 11ms @ 50 users | < 200ms @ peak |
| Error rate | < 2% | < 0.1% |

**Вердикт:** Приложение **не готово к production** в текущем виде.

---

## Выводы и рекомендации

### Общие выводы

1. **При малой-средней нагрузке (< 50 пользователей)** приложение работает отлично
   - Латентность < 15ms
   - Высокая стабильность
   - Минимум ошибок

2. **При высокой нагрузке (> 100 пользователей)** критические проблемы
   - Массивные ошибки 500 (4.68%)
   - Неприемлемая латентность (p95 = 3.1 сек)
   - Непредсказуемое поведение

3. **Узкое место: SQLite**
   - Не справляется с конкурентным доступом
   - Блокирует операции записи
   - Требует замены для production

### Критические рекомендации (приоритет: ВЫСОКИЙ)

#### 1. Миграция БД на PostgreSQL/MySQL

**Проблема:** SQLite не предназначена для высокой конкурентности

**Решение:**
```python
# Вместо SQLite
DATABASE_URL = "sqlite+aiosqlite:///./glossary.db"

# Использовать PostgreSQL
DATABASE_URL = "postgresql+asyncpg://user:password@localhost/glossary"
```

**Ожидаемый эффект:**
- Устранение блокировок при записи
- Поддержка множественных писателей
- Рост RPS в 5-10 раз


---

#### 2. Реализация Connection Pooling

**Проблема:** Каждый запрос создает новую сессию БД

**Решение:**
```python
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,          # Размер пула
    max_overflow=10,       # Дополнительные соединения
    pool_pre_ping=True,    # Проверка живых соединений
    pool_recycle=3600      # Переподключение каждый час
)

async_session = sessionmaker(
    engine, class_=AsyncSession, expire_on_commit=False
)
```

**Ожидаемый эффект:**
- Снижение латентности
- Уменьшение нагрузки на БД
- Повторное использование соединений


---

#### 3. Увеличение количества Uvicorn workers

**Проблема:** Используется только 1 воркер (режим разработки)

**Решение:**
```bash
# Вместо
uvicorn app.main:app --reload

# Использовать (production)
uvicorn app.main:app --workers 4 --host 0.0.0.0 --port 8000

# Или использовать Gunicorn
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

**Рекомендуемое количество воркеров:** `(2 * CPU cores) + 1`

**Ожидаемый эффект:**
- Параллельная обработка запросов
- Рост RPS
- Лучшее использование CPU

---

### Важные рекомендации (приоритет: СРЕДНИЙ)

#### 4. Внедрение кеширования

**Проблема:** Каждый запрос идет в БД, даже для часто запрашиваемых данных

**Решение:**
```python
from functools import lru_cache
from aiocache import cached, Cache
from aiocache.serializers import JsonSerializer

# Кеширование списка терминов (обновляется при изменении)
@cached(ttl=60, cache=Cache.MEMORY, serializer=JsonSerializer())
async def get_all_terms_cached(db: AsyncSession):
    result = await db.execute(select(Term).order_by(Term.title))
    return result.scalars().all()

# Кеширование конкретного термина
@cached(ttl=300, key_builder=lambda f, *args, **kwargs: f"term:{kwargs['keyword']}")
async def get_term_cached(keyword: str, db: AsyncSession):
    result = await db.execute(select(Term).where(Term.keyword == keyword))
    return result.scalar_one_or_none()
```

**Альтернатива:** Redis для распределенного кеша
```python
from aioredis import create_redis_pool

redis = await create_redis_pool('redis://localhost')
```

**Ожидаемый эффект:**
- Сильное снижение нагрузки на БД
- Снижение латентности GET запросов
- Рост RPS

---

#### 5. Добавление индексов в БД

**Проблема:** Нет индексов кроме primary key и unique constraint

**Решение:**
```python
from sqlalchemy import Index

class Term(Base):
    __tablename__ = "terms"

    id: Mapped[int] = mapped_column(Integer, primary_key=True, index=True)
    keyword: Mapped[str] = mapped_column(String(128), nullable=False)
    title: Mapped[str] = mapped_column(String(256), nullable=False)
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)

    # Добавить индексы
    __table_args__ = (
        UniqueConstraint("keyword", name="uq_terms_keyword"),
        Index("idx_terms_title", "title"),  # Для ORDER BY title
        Index("idx_terms_created_at", "created_at"),  # Для сортировки по дате
    )
```

**Ожидаемый эффект:**
- Ускорение запросов с ORDER BY
- Снижение латентности GET /terms

---

#### 6. Оптимизация запросов

**Проблема:** Некоторые запросы неоптимальны

**Решение 1:** Пагинация для GET /terms
```python
@router.get("", response_model=List[TermOut])
async def list_terms(
    skip: int = 0,
    limit: int = 100,
    db: AsyncSession = Depends(get_db)
):
    result = await db.execute(
        select(Term).order_by(Term.title).offset(skip).limit(limit)
    )
    return result.scalars().all()
```

**Решение 2:** Использовать SELECT COUNT(*) вместо загрузки всех записей
```python
@router.get("/count")
async def get_terms_count(db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(func.count(Term.id)))
    return {"count": result.scalar()}
```

**Ожидаемый эффект:**
- Снижение нагрузки на БД
- Снижение использования памяти
- Более предсказуемая производительность

---

### Дополнительные рекомендации (приоритет: НИЗКИЙ)

#### 7. Мониторинг и алертинг

**Внедрить:**
- Prometheus + Grafana для метрик
- Sentry для отслеживания ошибок
- Логирование запросов с correlation ID

```python
from prometheus_fastapi_instrumentator import Instrumentator

app = FastAPI()
Instrumentator().instrument(app).expose(app)
```

---

#### 8. Rate Limiting

**Защита от перегрузки:**
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@router.get("/terms")
@limiter.limit("100/minute")
async def list_terms(request: Request):
    ...
```

---

#### 9. Корректное завершение

**Обеспечить корректное завершение:**
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await create_all()
    yield
    # Shutdown
    await engine.dispose()  # Закрыть все соединения БД

app = FastAPI(lifespan=lifespan)
```


---

### Приоритизация рекомендаций

#### 1. Критические исправления
1. Миграция на PostgreSQL
2. Connection Pooling
3. Увеличение workers до 4

**Ожидаемый результат:** Рост RPS, отсутствие ошибок 500

---

#### 2. Оптимизация
4. Внедрение кеширования (Redis)
5. Добавление индексов
6. Оптимизация запросов

**Ожидаемый результат:** Рост RPS, снижение латентности

---

#### 3. Production-готовность
7. Мониторинг (Prometheus/Grafana)
8. Rate Limiting
9. Graceful Shutdown

**Ожидаемый результат:** Production-ready приложение

---

### Прогноз после внедрения рекомендаций

| Метрика | Текущее | После Фазы 1 | После Фазы 2 | Целевое (Production) |
|---------|---------|---------------|---------------|----------------------|
| Max stable users | 50 | 200 | 500 | 1000+ |
| RPS | 33 | 150-200 | 300-500 | 500-1000 |
| p95 latency | 11ms @ 50u | < 50ms | < 30ms | < 100ms |
| p99 latency | 14ms @ 50u | < 100ms | < 50ms | < 200ms |
| Error rate (500) | 0% @ 50u | < 0.1% | < 0.01% | < 0.01% |

---

## Заключение

Приложение **FastAPI Glossary API** демонстрирует:
- Отличную производительность при малой-средней нагрузке (< 50 пользователей)
- Хорошую стабильность при длительной работе
- Критические проблемы при высокой нагрузке (> 100 пользователей)

**Главная проблема:** Использование SQLite в качестве БД не подходит для production-окружения с высокой конкурентностью.

**Рекомендация:** Внедрить предложенные оптимизации в 3 фазы для достижения production-ready состояния.

**Текущий статус:** Подходит только для разработки и MVP. Требуется доработка перед production.

---

## Приложения

### Файлы с результатами тестов

Все результаты сохранены в директории [load_test_results/](load_test_results/):

- `test1_light_load.html` - HTML отчет легкой нагрузки
- `test1_light_load_stats.csv` - CSV с метриками
- `test2_working_load.html` - HTML отчет рабочей нагрузки
- `test2_working_load_stats.csv` - CSV с метриками
- `test3_stress_test.html` - HTML отчет стресс-теста
- `test3_stress_test_stats.csv` - CSV с метриками
- `test4_stability.html` - HTML отчет теста на стабильность
- `test4_stability_stats.csv` - CSV с метриками

### Команды для повторного запуска тестов

```bash
# Запуск приложения
uvicorn app.main:app --reload

# В отдельном терминале:

# Тест 1: Легкая нагрузка
locust -f locustfile.py --host=http://localhost:8000 \
    --users 10 --spawn-rate 2 --run-time 1m \
    --headless --html test1_light_load.html

# Тест 2: Рабочая нагрузка
locust -f locustfile.py --host=http://localhost:8000 \
    --users 50 --spawn-rate 5 --run-time 3m \
    --headless --html test2_working_load.html

# Тест 3: Стресс-тест
locust -f locustfile.py --host=http://localhost:8000 \
    --users 200 --spawn-rate 20 --run-time 5m \
    --headless --html test3_stress_test.html

# Тест 4: Тест на стабильность
locust -f locustfile.py --host=http://localhost:8000 \
    --users 50 --spawn-rate 5 --run-time 10m \
    --headless --html test4_stability.html
```

---
